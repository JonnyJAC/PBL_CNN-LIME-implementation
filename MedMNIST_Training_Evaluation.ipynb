{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6805be",
   "metadata": {},
   "source": [
    "\n",
    "# MedMNIST Model Training and Evaluation\n",
    "\n",
    "This notebook contains the code from `models.py` and `train_and_eval_pytorch.py`.\n",
    "\n",
    "## models.py\n",
    "This file defines the ResNet architectures (ResNet-18 and ResNet-50) used for image classification.\n",
    "\n",
    "## train_and_eval_pytorch.py\n",
    "This script handles the training and evaluation of the models on the MedMNIST dataset using PyTorch.\n",
    "\n",
    "You can run each cell to understand the structure of the models and the training process. Make sure that all necessary dependencies are installed before running the cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e34ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py content\n",
    "'''\n",
    "Adapted from kuangliu/pytorch-cifar .\n",
    "'''\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # 保存原始x的副本\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.relu(out + self.shortcut(identity))  # 使用非原地操作\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # 保存原始x的副本\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = F.relu(out + self.shortcut(identity))  # 使用非原地操作\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, in_channels=1, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(in_channels, num_classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def ResNet50(in_channels, num_classes):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], in_channels=in_channels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_eval_pytorch.py content\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "import medmnist\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from medmnist import INFO, Evaluator\n",
    "from models import ResNet18, ResNet50\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e245d3",
   "metadata": {},
   "source": [
    "### 训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def main(data_flag, output_root, num_epochs, gpu_ids, batch_size, download, model_flag, resize, as_rgb, model_path, run):\n",
    "\n",
    "    lr = 0.001\n",
    "    gamma=0.1\n",
    "    milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
    "\n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = 3 if as_rgb else info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    str_ids = gpu_ids.split(',')\n",
    "    gpu_ids = []\n",
    "    for str_id in str_ids:\n",
    "        id = int(str_id)\n",
    "        if id >= 0:\n",
    "            gpu_ids.append(id)\n",
    "    if len(gpu_ids) > 0:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_ids[0])\n",
    "\n",
    "    device = torch.device('cuda:{}'.format(gpu_ids[0])) if gpu_ids else torch.device('cpu') \n",
    "    \n",
    "    output_root = os.path.join(output_root, data_flag, time.strftime(\"%y%m%d_%H%M%S\"))\n",
    "    if not os.path.exists(output_root):\n",
    "        os.makedirs(output_root)\n",
    "\n",
    "    print('==> Preparing data...')\n",
    "\n",
    "    if resize:\n",
    "        data_transform = transforms.Compose(\n",
    "            [transforms.Resize((224, 224), interpolation=PIL.Image.NEAREST), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[.5], std=[.5])])\n",
    "    else:\n",
    "        data_transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[.5], std=[.5])])\n",
    "     \n",
    "    train_dataset = DataClass(split='train', transform=data_transform, download=download, as_rgb=as_rgb)\n",
    "    val_dataset = DataClass(split='val', transform=data_transform, download=download, as_rgb=as_rgb)\n",
    "    test_dataset = DataClass(split='test', transform=data_transform, download=download, as_rgb=as_rgb)\n",
    "\n",
    "    \n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    train_loader_at_eval = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "\n",
    "    print('==> Building and training model...')\n",
    "    \n",
    "    \n",
    "    if model_flag == 'resnet18':\n",
    "        model =  resnet18(pretrained=False, num_classes=n_classes) if resize else ResNet18(in_channels=n_channels, num_classes=n_classes)\n",
    "    elif model_flag == 'resnet50':\n",
    "        model =  resnet50(pretrained=False, num_classes=n_classes) if resize else ResNet50(in_channels=n_channels, num_classes=n_classes)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_evaluator = medmnist.Evaluator(data_flag, 'train')\n",
    "    val_evaluator = medmnist.Evaluator(data_flag, 'val')\n",
    "    test_evaluator = medmnist.Evaluator(data_flag, 'test')\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)\n",
    "        train_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, device, run, output_root)\n",
    "        val_metrics = test(model, val_evaluator, val_loader, task, criterion, device, run, output_root)\n",
    "        test_metrics = test(model, test_evaluator, test_loader, task, criterion, device, run, output_root)\n",
    "\n",
    "        print('train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2]) + \\\n",
    "              'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2]) + \\\n",
    "              'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2]))\n",
    "\n",
    "    if num_epochs == 0:\n",
    "        return\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "\n",
    "    logs = ['loss', 'auc', 'acc']\n",
    "    train_logs = ['train_'+log for log in logs]\n",
    "    val_logs = ['val_'+log for log in logs]\n",
    "    test_logs = ['test_'+log for log in logs]\n",
    "    log_dict = OrderedDict.fromkeys(train_logs+val_logs+test_logs, 0)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=os.path.join(output_root, 'Tensorboard_Results'))\n",
    "\n",
    "    best_auc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = deepcopy(model)\n",
    "\n",
    "    global iteration\n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in trange(num_epochs):        \n",
    "        train_loss = train(model, train_loader, task, criterion, optimizer, device, writer)\n",
    "        \n",
    "        train_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, device, run)\n",
    "        val_metrics = test(model, val_evaluator, val_loader, task, criterion, device, run)\n",
    "        test_metrics = test(model, test_evaluator, test_loader, task, criterion, device, run)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        for i, key in enumerate(train_logs):\n",
    "            log_dict[key] = train_metrics[i]\n",
    "        for i, key in enumerate(val_logs):\n",
    "            log_dict[key] = val_metrics[i]\n",
    "        for i, key in enumerate(test_logs):\n",
    "            log_dict[key] = test_metrics[i]\n",
    "\n",
    "        for key, value in log_dict.items():\n",
    "            writer.add_scalar(key, value, epoch)\n",
    "            \n",
    "        cur_auc = val_metrics[1]\n",
    "        if cur_auc > best_auc:\n",
    "            best_epoch = epoch\n",
    "            best_auc = cur_auc\n",
    "            best_model = deepcopy(model)\n",
    "            print('cur_best_auc:', best_auc)\n",
    "            print('cur_best_epoch', best_epoch)\n",
    "\n",
    "    state = {\n",
    "        'net': best_model.state_dict(),\n",
    "    }\n",
    "\n",
    "    path = os.path.join(output_root, 'best_model.pth')\n",
    "    torch.save(state, path)\n",
    "\n",
    "    train_metrics = test(best_model, train_evaluator, train_loader_at_eval, task, criterion, device, run, output_root)\n",
    "    val_metrics = test(best_model, val_evaluator, val_loader, task, criterion, device, run, output_root)\n",
    "    test_metrics = test(best_model, test_evaluator, test_loader, task, criterion, device, run, output_root)\n",
    "\n",
    "    train_log = 'train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2])\n",
    "    val_log = 'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2])\n",
    "    test_log = 'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2])\n",
    "\n",
    "    log = '%s\\n' % (data_flag) + train_log + val_log + test_log\n",
    "    print(log)\n",
    "            \n",
    "    with open(os.path.join(output_root, '%s_log.txt' % (data_flag)), 'a') as f:\n",
    "        f.write(log)  \n",
    "            \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def train(model, train_loader, task, criterion, optimizer, device, writer):\n",
    "    total_loss = []\n",
    "    global iteration\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = torch.squeeze(targets, 1).long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
    "        iteration += 1\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(model, evaluator, data_loader, task, criterion, device, run, save_folder=None):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = []\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            outputs = model(inputs.to(device))\n",
    "            \n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).to(device)\n",
    "                loss = criterion(outputs, targets)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs = m(outputs).to(device)\n",
    "            else:\n",
    "                targets = torch.squeeze(targets, 1).long().to(device)\n",
    "                loss = criterion(outputs, targets)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(outputs).to(device)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            total_loss.append(loss.item())\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc, acc = evaluator.evaluate(y_score, save_folder, run)\n",
    "        \n",
    "        test_loss = sum(total_loss) / len(total_loss)\n",
    "\n",
    "        return [test_loss, auc, acc]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# 在这里直接设置参数值\n",
    "data_flag = 'organamnist'\n",
    "output_root = './output'\n",
    "num_epochs = 10\n",
    "gpu_ids = '0'\n",
    "batch_size = 64\n",
    "download = False\n",
    "model_flag = 'resnet18'\n",
    "resize = True\n",
    "as_rgb = True\n",
    "model_path = None\n",
    "run = 'experiment_to_shap_2'\n",
    "\n",
    "# 调用main函数\n",
    "main(data_flag, output_root, num_epochs, gpu_ids, batch_size, download, model_flag, resize, as_rgb, model_path, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6063a",
   "metadata": {},
   "source": [
    "### LIME示例 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bb7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import medmnist\n",
    "from models import ResNet18  # 确保与您的模型定义一致\n",
    "data_flag = 'organamnist'\n",
    "output_root = './output'\n",
    "num_epochs = 10\n",
    "gpu_ids = '0'\n",
    "batch_size = 64\n",
    "download = False\n",
    "model_flag = 'resnet18'\n",
    "resize = True\n",
    "as_rgb = True\n",
    "model_path = \"C:\\\\Users\\\\10618\\\\Desktop\\\\experiments-main\\\\MedMNIST2D\\\\output\\\\organamnist\\\\231216_213642\\\\best_model.pth\"\n",
    "#model_path = \"C:\\\\Users\\\\10618\\\\Desktop\\\\experiments-main\\\\weights_organamnist\\\\resnet18_224_3.pth\"\n",
    "run = 'experiment_to_shap_2'\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "gamma=0.1\n",
    "milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = 3 if as_rgb else info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "str_ids = gpu_ids.split(',')\n",
    "gpu_ids = []\n",
    "for str_id in str_ids:\n",
    "    id = int(str_id)\n",
    "    if id >= 0:\n",
    "        gpu_ids.append(id)\n",
    "if len(gpu_ids) > 0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_ids[0])\n",
    "\n",
    "device = torch.device('cuda:{}'.format(gpu_ids[0])) if gpu_ids else torch.device('cpu') \n",
    "\n",
    "output_root = os.path.join(output_root, data_flag, time.strftime(\"%y%m%d_%H%M%S\"))\n",
    "if not os.path.exists(output_root):\n",
    "    os.makedirs(output_root)\n",
    "\n",
    "print('==> Preparing data...')\n",
    "\n",
    "if resize:\n",
    "    data_transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224), interpolation=PIL.Image.NEAREST), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[.5], std=[.5])])\n",
    "else:\n",
    "    data_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[.5], std=[.5])])\n",
    "\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download, as_rgb=as_rgb)\n",
    "val_dataset = DataClass(split='val', transform=data_transform, download=download, as_rgb=as_rgb)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download, as_rgb=as_rgb)\n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "\n",
    "print('==> Building and training model...')\n",
    "\n",
    "\n",
    "if model_flag == 'resnet18':\n",
    "    model =  resnet18(pretrained=False, num_classes=n_classes) if resize else ResNet18(in_channels=n_channels, num_classes=n_classes)\n",
    "elif model_flag == 'resnet50':\n",
    "    model =  resnet50(pretrained=False, num_classes=n_classes) if resize else ResNet50(in_channels=n_channels, num_classes=n_classes)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "train_evaluator = medmnist.Evaluator(data_flag, 'train')\n",
    "val_evaluator = medmnist.Evaluator(data_flag, 'val')\n",
    "test_evaluator = medmnist.Evaluator(data_flag, 'test')\n",
    "\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if model_path is not None:\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)\n",
    "    model.eval()\n",
    "        \n",
    "images, _ = next(iter(test_loader))\n",
    "images = images.to(device)  # 移动数据到相同的设备\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcda7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载数据集\n",
    "data = np.load('C:\\\\Users\\\\10618\\\\.medmnist\\\\organamnist.npz')\n",
    "\n",
    "X_test = data['test_images']  # 测试集图像\n",
    "y_test = data['test_labels']  # 测试集标签\n",
    "\n",
    "# 检查数据\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 选择几个样本\n",
    "num_samples_for_lime = 5  # 样本数量\n",
    "selected_indices = random.sample(range(len(X_test)), num_samples_for_lime)\n",
    "samples_for_lime = X_test[selected_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38feb413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 预处理函数\n",
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (224, 224))  # 调整大小\n",
    "    if len(img.shape) == 2:  # 如果是灰度图，转换为三通道\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = img.astype('float32') / 255  # 归一化\n",
    "    return img\n",
    "\n",
    "# 预处理样本\n",
    "preprocessed_samples = np.array([preprocess_image(img) for img in samples_for_lime])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "\n",
    "# 创建 LIME ImageExplainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# 选择一个样本\n",
    "sample = preprocessed_samples[0]  # 选择第一个样本\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64974c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(images):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 将图像转换为模型可接受的格式\n",
    "        images = torch.tensor(images.transpose((0, 3, 1, 2))).float()  # 从 NHWC 转换为 NCHW\n",
    "        \n",
    "        # 确定设备\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # 进行预测\n",
    "        preds = model(images)\n",
    "        \n",
    "        # 转换为概率\n",
    "        probs = torch.nn.functional.softmax(preds, dim=1).cpu().numpy()\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fa06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "\n",
    "# 创建分割算法，用于定义解释的超像素\n",
    "segmenter = SegmentationAlgorithm('slic', n_segments=100, compactness=1, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10df3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 对选定的样本生成 LIME 解释\n",
    "explanation = explainer.explain_instance(sample, model_predict, top_labels=5, hide_color=0, num_samples=1000, segmentation_fn=segmenter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "\n",
    "# 创建分割算法，用于定义解释的超像素\n",
    "segmenter = SegmentationAlgorithm('slic', n_segments=100, compactness=1, sigma=1)\n",
    "\n",
    "# 对选定的样本生成 LIME 解释\n",
    "explanation = explainer.explain_instance(sample, model_predict, top_labels=5, hide_color=0, num_samples=1000, segmentation_fn=segmenter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8811c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 可视化第一个预测类别的解释\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
    "\n",
    "plt.imshow(mark_boundaries(temp, mask))\n",
    "plt.title('LIME Explanation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b700be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_samples_for_lime = 81  # 选择 9x9 个样本\n",
    "selected_indices = random.sample(range(len(X_test)), num_samples_for_lime)\n",
    "samples_for_lime = X_test[selected_indices]\n",
    "\n",
    "# 预处理样本\n",
    "preprocessed_samples = np.array([preprocess_image(img) for img in samples_for_lime])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个解释器实例\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# 对每个样本进行 LIME 解释\n",
    "explanations = []\n",
    "predictions = []\n",
    "for sample in preprocessed_samples:\n",
    "    # 对样本进行解释\n",
    "    explanation = explainer.explain_instance(sample, model_predict, top_labels=3, hide_color=0, num_samples=100, segmentation_fn=segmenter)\n",
    "    explanations.append(explanation)\n",
    "    # 获取预测\n",
    "    prob = model_predict(sample[np.newaxis, ...])\n",
    "    prediction = np.argmax(prob, axis=1)[0]  # 取概率最高的类别\n",
    "    predictions.append(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561bedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示图像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "true_labels = y_test[selected_indices]\n",
    "\n",
    "# 显示图像、预测和解释\n",
    "fig, axs = plt.subplots(18, 9, figsize=(45, 90))  # 创建 18x9 的图表，因为每对图像需要两列\n",
    "\n",
    "for i, (sample, prediction, true_label) in enumerate(zip(samples_for_lime, predictions, true_labels)):\n",
    "    row = 2 * (i // 9)\n",
    "    col = i % 9\n",
    "    \n",
    "    # 显示原图、预测标签和真实标签\n",
    "    axs[row, col].imshow(sample, cmap='gray')\n",
    "    axs[row, col].set_title(f'Pred: {prediction}\\nTrue: {true_label}', fontsize=22)  # 显示预测和真实标签\n",
    "    axs[row, col].axis('off')\n",
    "    \n",
    "    # 显示解释图\n",
    "    temp, mask = explanations[i].get_image_and_mask(explanations[i].top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
    "    axs[row + 1, col].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    axs[row + 1, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First few predictions:\", predictions[:10])\n",
    "print(\"First few true labels:\", true_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(predictions) != len(true_labels):\n",
    "    print(\"Error: The number of predictions does not match the number of true labels.\")\n",
    "else:\n",
    "    # 将预测和真实标签转换为 NumPy 数组以便于计算\n",
    "    predictions_array = np.array(predictions)\n",
    "    true_labels_array = np.array(true_labels)\n",
    "\n",
    "true_labels_array = np.squeeze(true_labels)\n",
    "\n",
    "# 输出转换后的前几个真实标签进行比较\n",
    "print(\"First few true labels after squeezing:\", true_labels_array[:10])\n",
    "\n",
    "# 重新计算正确预测的数量和正确率\n",
    "correct_predictions = np.sum(predictions_array == true_labels_array)\n",
    "accuracy = correct_predictions / len(true_labels_array)\n",
    "print(f\"Correct Predictions: {correct_predictions}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示图像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 显示图像和解释\n",
    "fig, axs = plt.subplots(18, 9, figsize=(45, 90))  # 创建 18x9 的图表，每对图像需要两列\n",
    "\n",
    "for i, (sample, explanation, prediction) in enumerate(zip(samples_for_lime, explanations, predictions)):\n",
    "    row = 2 * (i // 9)\n",
    "    col = i % 9\n",
    "\n",
    "    # 显示原图及其预测\n",
    "    axs[row, col].imshow(sample, cmap='gray')\n",
    "    axs[row, col].set_title(f'Prediction: {prediction}', fontsize = 22)\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "    # 显示解释图\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=False, num_features=5, hide_rest=False)\n",
    "    axs[row+1, col].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    axs[row+1, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示图像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 显示图像和解释\n",
    "fig, axs = plt.subplots(18, 9, figsize=(45, 90))  # 创建 18x9 的图表，每对图像需要两列\n",
    "\n",
    "for i, (sample, explanation, prediction) in enumerate(zip(samples_for_lime, explanations, predictions)):\n",
    "    row = 2 * (i // 9)\n",
    "    col = i % 9\n",
    "\n",
    "    # 显示原图及其预测\n",
    "    axs[row, col].imshow(sample, cmap='gray')\n",
    "    axs[row, col].set_title(f'Prediction: {prediction}', fontsize = 22)\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "    # 显示解释图\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[2], positive_only=False, num_features=5, hide_rest=False)\n",
    "    axs[row+1, col].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    axs[row+1, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示多个标签的解释\n",
    "temp, mask = explanation.get_image_and_mask(label=explanation.top_labels[0], positive_only=True, num_features=10, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d624e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示正面影响的区域\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "#  'explanations' 是样本集生成的一系列解释\n",
    "for explanation in explanations:\n",
    "    num_labels = len(explanation.top_labels)\n",
    "    print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for explanation in explanations:\n",
    "    # 如果只有一个标签，需要特殊处理\n",
    "    if num_labels == 1:\n",
    "        fig, axs = plt.subplots(1, figsize=(6, 6))\n",
    "        axs = [axs]  # 将 axs 转换为一个列表\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, num_labels, figsize=(20, 10))\n",
    "\n",
    "    for i, label in enumerate(explanation.top_labels):\n",
    "        temp, mask = explanation.get_image_and_mask(label, positive_only=False, num_features=5, hide_rest=False)\n",
    "        axs[i].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "        axs[i].set_title(f'Label: {label}')\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 3  # 考虑的 top labels 数量\n",
    "num_columns = 1 + num_labels  # 1列原始图像 + num_labels 列 LIME 解释图\n",
    "\n",
    "# 对每个样本和对应的解释进行迭代\n",
    "for original, explanation in zip(preprocessed_samples, explanations):\n",
    "    fig, axs = plt.subplots(1, num_columns, figsize=(20, 5))  # 创建一行，num_columns 列的图表\n",
    "\n",
    "    # 显示原始图像\n",
    "    axs[0].imshow(original)\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # 显示每个 top label 的 LIME 解释图\n",
    "    for i, label in enumerate(explanation.top_labels[:num_labels]):\n",
    "        temp, mask = explanation.get_image_and_mask(label, positive_only=False, num_features=5, hide_rest=False)\n",
    "        axs[i + 1].imshow(mark_boundaries(temp / 2 + 0.5, mask))  # i + 1 因为第一列是原始图像\n",
    "        axs[i + 1].set_title(f'Label: {label}')\n",
    "        axs[i + 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique_labels, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebe962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个 9x9 的图表\n",
    "fig, axs = plt.subplots(5, 3, figsize=(8, 8))\n",
    "axs = axs.flatten()  # 将 axs 转换为一维数组以便于索引\n",
    "\n",
    "# 遍历每个唯一标签及其计数\n",
    "for i, (label, count) in enumerate(zip(unique_labels, counts)):\n",
    "    if i < 15:  # 只处理前 81 个标签\n",
    "        axs[i].text(0.5, 0.5, f'Label: {label}\\nCount: {count}', horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
    "        axs[i].axis('off')\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# 隐藏剩余的子图（如果有的话）\n",
    "for j in range(i, 15):\n",
    "    axs[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7990b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wasted\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='RUN Baseline model of MedMNIST2D')\n",
    "\n",
    "    parser.add_argument('--data_flag',\n",
    "                        default='pathmnist',\n",
    "                        type=str)\n",
    "    parser.add_argument('--output_root',\n",
    "                        default='./output',\n",
    "                        help='output root, where to save models and results',\n",
    "                        type=str)\n",
    "    parser.add_argument('--num_epochs',\n",
    "                        default=100,\n",
    "                        help='num of epochs of training, the script would only test model if set num_epochs to 0',\n",
    "                        type=int)\n",
    "    parser.add_argument('--gpu_ids',\n",
    "                        default='0',\n",
    "                        type=str)\n",
    "    parser.add_argument('--batch_size',\n",
    "                        default=128,\n",
    "                        type=int)\n",
    "    parser.add_argument('--download',\n",
    "                        action=\"store_true\")\n",
    "    parser.add_argument('--resize',\n",
    "                        help='resize images of size 28x28 to 224x224',\n",
    "                        action=\"store_true\")\n",
    "    parser.add_argument('--as_rgb',\n",
    "                        help='convert the grayscale image to RGB',\n",
    "                        action=\"store_true\")\n",
    "    parser.add_argument('--model_path',\n",
    "                        default=None,\n",
    "                        help='root of the pretrained model to test',\n",
    "                        type=str)\n",
    "    parser.add_argument('--model_flag',\n",
    "                        default='resnet18',\n",
    "                        help='choose backbone from resnet18, resnet50',\n",
    "                        type=str)\n",
    "    parser.add_argument('--run',\n",
    "                        default='model1',\n",
    "                        help='to name a standard evaluation csv file, named as {flag}_{split}_[AUC]{auc:.3f}_[ACC]{acc:.3f}@{run}.csv',\n",
    "                        type=str)\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    data_flag = args.data_flag\n",
    "    output_root = args.output_root\n",
    "    num_epochs = args.num_epochs\n",
    "    gpu_ids = args.gpu_ids\n",
    "    batch_size = args.batch_size\n",
    "    download = args.download\n",
    "    model_flag = args.model_flag\n",
    "    resize = args.resize\n",
    "    as_rgb = args.as_rgb\n",
    "    model_path = args.model_path\n",
    "    run = args.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
